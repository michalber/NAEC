{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This notebook is used to prepare Excel sheets with all training data\n",
    "It divides all real and synthetic data into train and ground-truth data paths.\n",
    "Three folders are used to create dataset: `real`, `real_doubled` and `synthetic`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we need to include all required libs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create global paths used in notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "CUR_PATH = os.getcwd()\n",
    "DATA_PATH_PREFIX = CUR_PATH.replace(\"notebooks\", \"data\") + \"/AEC-Challenge/datasets/\"\n",
    "DATA_PATHS = [DATA_PATH_PREFIX + \"test_set\", DATA_PATH_PREFIX + \"test_set_interspeech2021\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check if folders we want to use exists"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "for path_ in DATA_PATHS:\n",
    "    if(not path.exists(path_)):\n",
    "        logging.error(\"%s is not existing!\", path_)\n",
    "        raise Exception()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create list of file postfixes to later search one of them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "EXCLUDE_FILEENDINGS = [\"doubletalk\",\n",
    "                       \"farend\",\n",
    "                       \"nearend\"\n",
    "                       \"sweep\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Training Dataset from Real Recordings\n",
    "Crate list of directories containing real recordings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "TEST_PATHS = [DATA_PATH_PREFIX + \"test_set/clean\", DATA_PATH_PREFIX + \"test_set/noisy\",\n",
    "              DATA_PATH_PREFIX + \"test_set_interspeech2021\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Regex object to find one of excluded file postfixes and define function to perform Regex action on given filename"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "to_find = re.compile(\"doubletalk|farend|nearend|sweep\")\n",
    "\n",
    "def get_recording_id(filename_pv):\n",
    "    try:\n",
    "        match_obj = to_find.search(filename)\n",
    "        the_index = match_obj.start()\n",
    "        return filename[:the_index]\n",
    "    except:\n",
    "        return \"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define function to save real recording to Excel sheet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def save_record_to_csv(work_dir, record_id, out_df):\n",
    "    BASE_PATH = \"\"\n",
    "    if work_dir != TEST_PATHS[-1]:\n",
    "        BASE_PATH = work_dir + \"/\" + record_id\n",
    "    else:\n",
    "        BASE_PATH = work_dir + \"/\"\n",
    "\n",
    "    # doubletalk_clean = \"\"\n",
    "    # doubletalk_mic = \"\"\n",
    "    # doubletalk_w_mv_clean = \"\"\n",
    "    # doubletalk_w_mv_mic = \"\"\n",
    "    # farend_s_t_clean = \"\"\n",
    "    # farend_s_t_mic = \"\"\n",
    "    # farend_s_t_w_mv_clean = \"\"\n",
    "    # farend_s_t_w_mv_mic = \"\"\n",
    "    # nearend_mic = \"\"\n",
    "    sweep_lpb = \"\"\n",
    "    sweep_mic = \"\"\n",
    "\n",
    "    if work_dir != TEST_PATHS[-1]:\n",
    "        doubletalk_clean = BASE_PATH + \"doubletalk/\" + \"doubletalk_lpb.wav\"\n",
    "        doubletalk_mic = BASE_PATH + \"doubletalk/\" + \"doubletalk_mic.wav\"\n",
    "\n",
    "        doubletalk_w_mv_clean = BASE_PATH + \"doubletalk/\" + \"doubletalk_with_movement_lpb.wav\"\n",
    "        doubletalk_w_mv_mic = BASE_PATH + \"doubletalk/\" + \"doubletalk_with_movement_mic.wav\"\n",
    "\n",
    "        farend_s_t_clean = BASE_PATH + \"farend-singletalk/\" + \"farend_singletalk_lpb.wav\"\n",
    "        farend_s_t_mic = BASE_PATH + \"farend-singletalk/\" + \"farend_singletalk_mic.wav\"\n",
    "\n",
    "        farend_s_t_w_mv_clean = BASE_PATH + \"farend-singletalk/\" + \"farend_singletalk_with_movement_lpb.wav\"\n",
    "        farend_s_t_w_mv_mic = BASE_PATH + \"farend-singletalk/\" + \"farend_singletalk_with_movement_mic.wav\"\n",
    "\n",
    "        nearend_mic = BASE_PATH + \"nearend-singletalk/\" + \"nearend_singletalk_mic.wav\"\n",
    "\n",
    "    else:\n",
    "        doubletalk_clean = BASE_PATH + \"doubletalk_lpb.wav\"\n",
    "        doubletalk_mic = BASE_PATH + \"doubletalk_mic.wav\"\n",
    "\n",
    "        doubletalk_w_mv_clean = BASE_PATH + \"doubletalk_with_movement_lpb.wav\"\n",
    "        doubletalk_w_mv_mic = BASE_PATH + \"doubletalk_with_movement_mic.wav\"\n",
    "\n",
    "        farend_s_t_clean = BASE_PATH + \"farend_singletalk_lpb.wav\"\n",
    "        farend_s_t_mic = BASE_PATH + \"farend_singletalk_mic.wav\"\n",
    "\n",
    "        farend_s_t_w_mv_clean = BASE_PATH + \"farend_singletalk_with_movement_lpb.wav\"\n",
    "        farend_s_t_w_mv_mic = BASE_PATH + \"farend_singletalk_with_movement_mic.wav\"\n",
    "\n",
    "        nearend_mic = BASE_PATH + \"nearend_singletalk_mic.wav\"\n",
    "\n",
    "\n",
    "    data_row = dict()\n",
    "\n",
    "    data_row[\"ID\"] = record_id\n",
    "\n",
    "    if os.path.isfile(doubletalk_clean):\n",
    "        data_row[\"DT Clean\"] = doubletalk_clean\n",
    "    else: data_row[\"DT Clean\"] = \"\"\n",
    "\n",
    "    if os.path.isfile(doubletalk_mic):\n",
    "        data_row[\"DT Mic\"] = doubletalk_mic\n",
    "    else: data_row[\"DT Mic\"] = \"\"\n",
    "\n",
    "    if os.path.isfile(doubletalk_w_mv_clean):\n",
    "       data_row[\"DT MV Clean\"] = doubletalk_w_mv_clean\n",
    "    else: data_row[\"DT MV Clean\"] = \"\"\n",
    "    if os.path.isfile(doubletalk_w_mv_mic):\n",
    "        data_row[\"DT MV Mic\"] = doubletalk_w_mv_clean\n",
    "    else: data_row[\"DT MV Mic\"] = \"\"\n",
    "\n",
    "    if os.path.isfile(farend_s_t_clean):\n",
    "        data_row[\"FE Clean\"] = farend_s_t_clean\n",
    "    else: data_row[\"FE Clean\"] = \"\"\n",
    "    if os.path.isfile(farend_s_t_mic):\n",
    "        data_row[\"FE Mic\"] = farend_s_t_mic\n",
    "    else: data_row[\"FE Mic\"] = \"\"\n",
    "\n",
    "    if os.path.isfile(farend_s_t_w_mv_clean):\n",
    "        data_row[\"FE MV Clean\"] = farend_s_t_w_mv_clean\n",
    "    else: data_row[\"FE MV Clean\"] = \"\"\n",
    "    if os.path.isfile(farend_s_t_w_mv_mic):\n",
    "        data_row[\"FE MV Mic\"] = farend_s_t_w_mv_mic\n",
    "    else: data_row[\"FE MV Mic\"] = \"\"\n",
    "\n",
    "    if os.path.isfile(nearend_mic):\n",
    "        data_row[\"NE Clean\"] = nearend_mic\n",
    "    else: data_row[\"NE Clean\"] = \"\"\n",
    "\n",
    "    if os.path.isfile(sweep_lpb):\n",
    "        data_row[\"SP Clean\"] = sweep_lpb\n",
    "    else: data_row[\"SP Clean\"] = \"\"\n",
    "    if os.path.isfile(sweep_mic):\n",
    "        data_row[\"SP Mic\"] = sweep_mic\n",
    "    else: data_row[\"SP Mic\"] = \"\"\n",
    "\n",
    "    return out_df.append(data_row, ignore_index = True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Pandas DataFrame object to save recordings records"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "cols = [\"ID\", \"DT Clean\", \"DT Mic\", \"DT MV Clean\", \"DT MV Mic\", \"FE Clean\", \"FE Mic\", \"FE MV Clean\", \"FE MV Mic\", \"NE Clean\", \"SP Clean\", \"SP Mic\"]\n",
    "recs_df = pd.DataFrame(columns = cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For every directory, gather unique IDs and save recordings accordingly to columns in DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 unique IDs in D:\\Repos\\NAEC\\data/AEC-Challenge/datasets/test_set/clean directory.\n",
      "Found 100 unique IDs in D:\\Repos\\NAEC\\data/AEC-Challenge/datasets/test_set/noisy directory.\n",
      "Found 426 unique IDs in D:\\Repos\\NAEC\\data/AEC-Challenge/datasets/test_set_interspeech2021 directory.\n"
     ]
    }
   ],
   "source": [
    "for tr_dir in TEST_PATHS:\n",
    "    recordings_ids = []\n",
    "\n",
    "    tst_dir = []\n",
    "    if tr_dir == TEST_PATHS[-1]:\n",
    "        tst_dir = [tr_dir + \"/doubletalk\", tr_dir + \"/farend-singletalk\", tr_dir + \"/nearend-singletalk\"]\n",
    "    else:\n",
    "        tst_dir = [tr_dir]\n",
    "\n",
    "    for dir in tst_dir:\n",
    "        for filename in os.listdir(dir):\n",
    "            rec_id = get_recording_id(filename)\n",
    "            if rec_id != \"\":\n",
    "                recordings_ids.append(rec_id)\n",
    "\n",
    "    recordings_ids = list(set(recordings_ids))\n",
    "    print(\"Found {} unique IDs in {} directory.\".format(len(recordings_ids), tr_dir))\n",
    "\n",
    "    for ids in recordings_ids:\n",
    "        recs_df = save_record_to_csv(tr_dir, ids, recs_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Training Dataset from Synthetic Recordings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define function to save synthetic recodings to Excel sheet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def save_synth_record_to_csv(work_dir, record_id, out_df):\n",
    "    BASE_PATH = work_dir\n",
    "\n",
    "    doubletalk_clean = BASE_PATH + \"nearend_speech/\" + \"nearend_speech_fileid_{}.wav\".format(record_id)\n",
    "    doubletalk_mic = BASE_PATH + \"nearend_mic_signal/\" + \"nearend_mic_fileid_{}.wav\".format(record_id)\n",
    "\n",
    "    farend_mic = BASE_PATH + \"farend_speech/\" + \"farend_speech_fileid_{}.wav\".format(record_id)\n",
    "\n",
    "    nearend_mic = BASE_PATH + \"nearend_speech/\" + \"nearend_speech_fileid_{}.wav\".format(record_id)\n",
    "\n",
    "    data_row = dict()\n",
    "\n",
    "    data_row[\"ID\"] = str(record_id)\n",
    "\n",
    "    if os.path.isfile(doubletalk_clean):\n",
    "        data_row[\"DT Clean\"] = doubletalk_clean\n",
    "    else: data_row[\"DT Clean\"] = \"\"\n",
    "\n",
    "    if os.path.isfile(doubletalk_mic):\n",
    "        data_row[\"DT Mic\"] = doubletalk_mic\n",
    "    else: data_row[\"DT Mic\"] = \"\"\n",
    "\n",
    "\n",
    "    data_row[\"DT MV Clean\"] = \"\"\n",
    "    data_row[\"DT MV Mic\"] = \"\"\n",
    "\n",
    "    data_row[\"FE Clean\"] = \"\"\n",
    "\n",
    "    if os.path.isfile(farend_mic):\n",
    "        data_row[\"FE Mic\"] = farend_mic\n",
    "    else: data_row[\"FE Mic\"] = \"\"\n",
    "\n",
    "    data_row[\"FE MV Clean\"] = \"\"\n",
    "    data_row[\"FE MV Mic\"] = \"\"\n",
    "\n",
    "    if os.path.isfile(nearend_mic):\n",
    "        data_row[\"NE Clean\"] = nearend_mic\n",
    "    else: data_row[\"NE Clean\"] = \"\"\n",
    "\n",
    "    data_row[\"SP Clean\"] = \"\"\n",
    "    data_row[\"SP Mic\"] = \"\"\n",
    "\n",
    "    return out_df.append(data_row, ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read provided CSV file and save only training data to Excel sheet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "SYNTH_PATH = DATA_PATH_PREFIX + \"synthetic/\"\n",
    "synth_df = pd.read_csv(SYNTH_PATH + \"meta.csv\")\n",
    "for idx, row in synth_df.iterrows():\n",
    "    if row[\"split\"] == \"test\":\n",
    "        recs_df = save_synth_record_to_csv(SYNTH_PATH, row[\"fileid\"], recs_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save data to Excel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "synth_df.to_excel(\"meta.xlsx\")\n",
    "recs_df.to_excel(\"test_data.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}