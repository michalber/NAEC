{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "import os, fnmatch\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from random import shuffle, seed\n",
    "import numpy as np\n",
    "from wavinfo import WavInfoReader\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from threading import Lock\n",
    "from multiprocessing import Pool, RLock, freeze_support\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM, Dropout,\\\n",
    "    Lambda, Input, Multiply, Layer, Conv1D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, CSVLogger,\\\n",
    "    EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, GRU\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from librosa.util import frame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "class audio_generator:\n",
    "    '''\n",
    "    Class to create a Tensorflow dataset based on an iterator from a large scale\n",
    "    audio dataset. This audio generator only supports single channel audio files.\n",
    "    '''\n",
    "    def __init__(self, path_to_input, path_to_s1, len_of_chunks, nfft, window_size_samples, stride_size_samples, train_flag=False):\n",
    "        '''\n",
    "        Constructor of the audio generator class.\n",
    "        Inputs:\n",
    "            path_to_input       path to the mixtures\n",
    "            path_to_s1          path to the target source data\n",
    "            len_of_samples      length of audio snippets in samples\n",
    "            fs                  sampling rate\n",
    "            train_flag          flag for activate shuffling of files\n",
    "        '''\n",
    "        # set inputs to properties\n",
    "        self.total_samples = 0\n",
    "        self.path_to_input = path_to_input\n",
    "        self.path_to_s1 = path_to_s1\n",
    "        self.len_of_chunks = len_of_chunks\n",
    "        self.nfft = nfft\n",
    "        self.window_size_samples = window_size_samples\n",
    "        self.stride_size_samples = stride_size_samples\n",
    "        self.train_flag=train_flag\n",
    "        # count the number of samples in your data set (depending on your disk,\n",
    "        #                                               this can take some time)\n",
    "        self.mutex = Lock()\n",
    "        self.count_samples()\n",
    "        # create iterable tf.data.Dataset object\n",
    "        self.create_tf_data_obj()\n",
    "\n",
    "    def number_of_chunks(self, len_of_audio, chunk_size, stride_size):\n",
    "        return 1 + int((len_of_audio - chunk_size) / stride_size)\n",
    "\n",
    "    def process_file(self, filename):\n",
    "        info = WavInfoReader(os.path.join(self.path_to_input, filename))\n",
    "        num_of_chunks = int(np.fix(self.number_of_chunks(info.data.frame_count, self.window_size_samples, self.stride_size_samples)/self.len_of_chunks))\n",
    "        num_of_chunks = self.number_of_chunks(num_of_chunks, self.len_of_chunks, self.len_of_chunks)\n",
    "        self.mutex.acquire()\n",
    "        self.total_samples = self.total_samples + num_of_chunks\n",
    "        self.mutex.release()\n",
    "\n",
    "    def count_samples(self):\n",
    "        '''\n",
    "        Method to list the data of the dataset and count the number of samples.\n",
    "        '''\n",
    "\n",
    "        # list .wav files in directory\n",
    "        self.file_names = fnmatch.filter(os.listdir(self.path_to_input), '*.wav')\n",
    "        # count the number of samples contained in the dataset\n",
    "        self.total_samples = 0\n",
    "\n",
    "        data_path = os.path.join(self.path_to_input, self.file_names[0])\n",
    "        self.data_shape = self.convert_audio_to_spectrogram(str(data_path), self.nfft, self.window_size_samples, self.stride_size_samples).shape\n",
    "        # freeze_support()  # for Windows support\n",
    "        # thread_map(self.process_file, self.file_names, chunksize=16)\n",
    "        self.total_samples = 1700\n",
    "        print(f\"Found {self.total_samples} different chunks\")\n",
    "\n",
    "    def convert_audio_to_spectrogram(self, filepath, nfft, window_size_samples, stride_size_samples):\n",
    "        audio = tfio.audio.AudioIOTensor(filepath)\n",
    "        audio_slice = audio[:]\n",
    "        audio_tensor = tf.squeeze(audio_slice, axis=[-1])\n",
    "        if audio_tensor.dtype != tf.float32:\n",
    "            audio_tensor = tf.cast(audio_tensor, tf.float32) / 32768.0\n",
    "        spectrogram = tfio.audio.spectrogram(\n",
    "            audio_tensor, nfft=nfft, window=window_size_samples, stride=stride_size_samples)\n",
    "\n",
    "        spectrogram = tf.math.log(spectrogram).numpy()\n",
    "        return spectrogram\n",
    "\n",
    "    def create_generator(self):\n",
    "        '''\n",
    "        Method to create the iterator.\n",
    "        '''\n",
    "\n",
    "        # check if training or validation\n",
    "        if self.train_flag:\n",
    "            shuffle(self.file_names)\n",
    "        # iterate over the files\n",
    "        for file in self.file_names:\n",
    "            noisy_path = os.path.join(self.path_to_input, file)\n",
    "            clean_file = file.replace(\"_xdata\", \"_ydata\")\n",
    "            clean_path = os.path.join(self.path_to_s1, clean_file)\n",
    "\n",
    "            # Calc STFT\n",
    "            noisy_stft = self.convert_audio_to_spectrogram(str(noisy_path), self.nfft, self.window_size_samples, self.stride_size_samples)\n",
    "            clean_stft = self.convert_audio_to_spectrogram(str(clean_path), self.nfft, self.window_size_samples, self.stride_size_samples)\n",
    "\n",
    "            if noisy_stft.shape != clean_stft.shape:\n",
    "                raise ValueError('Data shapes do not match.')\n",
    "\n",
    "            # Count number of (len_of_chunks, NFFT/2+1) chunks in STFT\n",
    "            segmented_data_x = frame(noisy_stft, frame_length=self.len_of_chunks, hop_length=self.len_of_chunks, axis=0)\n",
    "            segmented_data_y = frame(clean_stft, frame_length=self.len_of_chunks, hop_length=self.len_of_chunks, axis=0)\n",
    "\n",
    "            if np.isnan(segmented_data_x).any():\n",
    "                print(segmented_data_x)\n",
    "                raise ValueError(\"NaN\")\n",
    "\n",
    "            if np.isnan(segmented_data_y).any():\n",
    "                print(segmented_data_y)\n",
    "                raise ValueError(\"NaN\")\n",
    "\n",
    "            if segmented_data_x.shape != segmented_data_y.shape:\n",
    "                raise ValueError('Data shapes do not match.')\n",
    "\n",
    "            # iterate over the number of samples\n",
    "            for idx in range(segmented_data_x.shape[0]):\n",
    "                # yield the chunks as float32 data\n",
    "                yield segmented_data_x[idx].astype('float32'), segmented_data_y[idx].astype('float32')\n",
    "\n",
    "\n",
    "    def create_tf_data_obj(self):\n",
    "        '''\n",
    "        Method to to create the tf.data.Dataset.\n",
    "        '''\n",
    "        # creating the tf.data.Dataset from the iterator\n",
    "        self.tf_data_set = tf.data.Dataset.from_generator(\n",
    "            self.create_generator,\n",
    "            (tf.float32, tf.float32),\n",
    "            output_shapes=(tf.TensorShape([self.len_of_chunks, self.data_shape[1]]),\n",
    "                           tf.TensorShape([self.len_of_chunks, self.data_shape[1]])),\n",
    "            args=None)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAEC_model:\n",
    "    def __init__(self):\n",
    "        # defining default cost function\n",
    "        self.cost_function = self.snr_cost\n",
    "        # empty property for the model\n",
    "        self.model = []\n",
    "        # defining default parameters\n",
    "        self.batchsize = 32\n",
    "\n",
    "        self.chunk_len = 10\n",
    "        self.nfft = 512\n",
    "        self.block_shift = int(self.nfft * 0.5)\n",
    "\n",
    "        self.activation = 'sigmoid'\n",
    "\n",
    "        self.numUnits = 128\n",
    "        self.numLayer = 2\n",
    "\n",
    "        self.dropout = 0.25\n",
    "        self.lr = 1e-5\n",
    "        self.max_epochs = 1\n",
    "        self.encoder_size = 256\n",
    "        self.eps = 1e-7\n",
    "\n",
    "        self.mse_loss = keras.losses.MeanSquaredError()\n",
    "        # reset all seeds to 42 to reduce invariance between training runs\n",
    "        os.environ['PYTHONHASHSEED'] = str(42)\n",
    "        seed(42)\n",
    "        np.random.seed(42)\n",
    "\n",
    "    @staticmethod\n",
    "    def snr_cost(s_estimate, s_true, s_input):\n",
    "        '''\n",
    "        Static Method defining the cost function.\n",
    "        The negative signal to noise ratio is calculated here. The loss is\n",
    "        always calculated over the last dimension.\n",
    "        '''\n",
    "\n",
    "        # # calculating the SNR\n",
    "        # snr = tf.reduce_mean(tf.math.square(s_true), axis=-1, keepdims=True) /\\\n",
    "        #       (tf.reduce_mean(tf.math.square(s_true - s_estimate), axis=-1, keepdims=True) + 1e-7)\n",
    "        #\n",
    "        # # using some more lines, because TF has no log10\n",
    "        # num = tf.math.log(snr)\n",
    "        # denom = tf.math.log(tf.constant(10, dtype=num.dtype))\n",
    "        # loss = -10 * (num / denom)\n",
    "        # # returning the loss\n",
    "        out_vals = s_input * s_estimate\n",
    "        loss = keras.losses.MSE(out_vals, s_estimate)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def lossWrapper(self):\n",
    "        '''\n",
    "        A wrapper function which returns the loss function. This is done to\n",
    "        to enable additional arguments to the loss function if necessary.\n",
    "        '''\n",
    "\n",
    "        def lossFunction(y_true, y_pred):\n",
    "            # calculating loss and squeezing single dimensions away\n",
    "            loss = tf.squeeze(self.cost_function(y_pred, y_true))\n",
    "            # calculate mean over batches\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            # return the loss\n",
    "            # pred_data, input_data = y_pred\n",
    "            # out_vals = input_data * pred_data\n",
    "            # loss = keras.losses.MSE(y_pred, y_true)\n",
    "            return loss\n",
    "\n",
    "        # returning the loss function as handle\n",
    "        return lossFunction\n",
    "\n",
    "    def create_model(self):\n",
    "        '''\n",
    "        Method to build and compile the NAEC model. The model takes frequency\n",
    "        domain batches of size (batchsize, chunk_len, nfft/2 + 1) and returns\n",
    "        enhanced clips in the same dimensions.\n",
    "        '''\n",
    "\n",
    "        # input layer for time signal\n",
    "        input_output_shape = (self.chunk_len, int(self.nfft / 2) + 1)\n",
    "        freq_dat = Input(batch_shape=(None, self.chunk_len, int(self.nfft / 2) + 1))\n",
    "        self.input_freq_layer = freq_dat\n",
    "\n",
    "        # gru_layer = GRU(int(self.nfft / 2) + 1, activation='tanh', input_shape=input_output_shape, return_sequences=True)(freq_dat)\n",
    "        mag_norm = InstantLayerNormalization()(freq_dat)\n",
    "        gru_layer = LSTM(int(self.nfft / 2) + 1, activation='relu', input_shape=input_output_shape, return_sequences=True)(mag_norm)\n",
    "        estimated_mag = Multiply()([freq_dat, gru_layer])\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=freq_dat, outputs=estimated_mag)\n",
    "        # show the model summary\n",
    "        self.model.summary()\n",
    "\n",
    "\n",
    "    def compile_model(self):\n",
    "        '''\n",
    "        Method to compile the model for training\n",
    "        '''\n",
    "        # use the Adam optimizer with a clipnorm of 3\n",
    "        optimizer_adam = keras.optimizers.Adam(learning_rate=self.lr, clipnorm=1, decay=1e-3)\n",
    "        # compile model with loss function\n",
    "        # self.model.compile(loss=self.lossWrapper(), optimizer=optimizer_adam, metrics=['accuracy'])\n",
    "        self.model.compile(loss='mean_squared_error', optimizer=optimizer_adam, metrics=['accuracy'])\n",
    "        # model.compile(loss=custom_loss(input_layer),optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    def train_model(self, run_name, path_to_train_x, path_to_train_y,\n",
    "                    path_to_val_x, path_to_val_y):\n",
    "        '''\n",
    "        Method to train the DTLN model.\n",
    "        '''\n",
    "        print(\"Train NAEC model\")\n",
    "        # create save path if not existent\n",
    "        ct = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        save_path = str(Path(\"./models/\" + str(ct)).mkdir(parents=True, exist_ok=True)) + '/' + run_name + '/'\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        print(f\"Save path: {save_path}\")\n",
    "\n",
    "        # create log file writer\n",
    "        csv_logger = CSVLogger(save_path + 'training_' + run_name + '.log')\n",
    "        # create callback for the adaptive learning rate\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                      patience=3, min_lr=10 ** (-10), cooldown=1)\n",
    "        # create callback for early stopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0,\n",
    "                                       patience=10, verbose=0, mode='auto', baseline=None)\n",
    "        # create model check pointer to save the best model\n",
    "        checkpointer = ModelCheckpoint(save_path + run_name + '.h5',\n",
    "                                       monitor='val_loss',\n",
    "                                       verbose=1,\n",
    "                                       save_best_only=True,\n",
    "                                       save_weights_only=False,\n",
    "                                       mode='auto',\n",
    "                                       save_freq='epoch'\n",
    "                                       )\n",
    "\n",
    "        # create data generator for training data\n",
    "        print(\"Load training data\")\n",
    "        generator_input = audio_generator(path_to_train_x,\n",
    "                                          path_to_train_y,\n",
    "                                          self.chunk_len,\n",
    "                                          self.nfft,\n",
    "                                          self.nfft,\n",
    "                                          self.block_shift,\n",
    "                                          train_flag=True)\n",
    "        dataset = generator_input.tf_data_set\n",
    "        dataset = dataset.batch(self.batchsize, drop_remainder=True).repeat()\n",
    "        # calculate number of training steps in one epoch\n",
    "        steps_train = generator_input.total_samples // self.batchsize\n",
    "\n",
    "        print(\"Training generator: {}\".format(dataset))\n",
    "        print(\"Training steps count: {}\".format(steps_train))\n",
    "\n",
    "        # create data generator for validation data\n",
    "        print(\"Load validation data\")\n",
    "        generator_val = audio_generator(path_to_val_x,\n",
    "                                        path_to_val_y,\n",
    "                                        self.chunk_len,\n",
    "                                        self.nfft,\n",
    "                                        self.nfft,\n",
    "                                        self.block_shift,\n",
    "                                        train_flag=False)\n",
    "        dataset_val = generator_val.tf_data_set\n",
    "        dataset_val = dataset_val.batch(self.batchsize, drop_remainder=True).repeat()\n",
    "        # calculate number of validation steps\n",
    "        steps_val = generator_val.total_samples // self.batchsize\n",
    "\n",
    "        print(\"Validation generator: {}\".format(dataset_val))\n",
    "        print(\"Validation steps count: {}\".format(steps_val))\n",
    "\n",
    "        # start the training of the model\n",
    "        self.model.fit(\n",
    "            x=dataset,\n",
    "            batch_size=None,\n",
    "            steps_per_epoch=steps_train,\n",
    "            epochs=self.max_epochs,\n",
    "            verbose=1,\n",
    "            validation_data=dataset_val,\n",
    "            validation_steps=steps_val,\n",
    "            callbacks=[checkpointer, reduce_lr, early_stopping],\n",
    "            max_queue_size=50,\n",
    "            workers=4,\n",
    "            use_multiprocessing=True)\n",
    "        # clear out garbage\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "class InstantLayerNormalization(Layer):\n",
    "    '''\n",
    "    Class implementing instant layer normalization. It can also be called\n",
    "    channel-wise layer normalization and was proposed by\n",
    "    Luo & Mesgarani (https://arxiv.org/abs/1809.07454v2)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        '''\n",
    "            Constructor\n",
    "        '''\n",
    "        super(InstantLayerNormalization, self).__init__(**kwargs)\n",
    "        self.epsilon = 1e-7\n",
    "        self.gamma = None\n",
    "        self.beta = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        '''\n",
    "        Method to build the weights.\n",
    "        '''\n",
    "        shape = input_shape[-1:]\n",
    "        # initialize gamma\n",
    "        self.gamma = self.add_weight(shape=shape,\n",
    "                                     initializer='ones',\n",
    "                                     trainable=True,\n",
    "                                     name='gamma')\n",
    "        # initialize beta\n",
    "        self.beta = self.add_weight(shape=shape,\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True,\n",
    "                                    name='beta')\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        '''\n",
    "        Method to call the Layer. All processing is done here.\n",
    "        '''\n",
    "\n",
    "        # calculate mean of each frame\n",
    "        mean = tf.math.reduce_mean(inputs, axis=[-1], keepdims=True)\n",
    "        # calculate variance of each frame\n",
    "        variance = tf.math.reduce_mean(tf.math.square(inputs - mean),\n",
    "                                       axis=[-1], keepdims=True)\n",
    "        # calculate standard deviation\n",
    "        std = tf.math.sqrt(variance + self.epsilon)\n",
    "        # normalize each frame independently\n",
    "        outputs = (inputs - mean) / std\n",
    "        # scale with gamma\n",
    "        outputs = outputs * self.gamma\n",
    "        # add the bias beta\n",
    "        outputs = outputs + self.beta\n",
    "        # return output\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "CUR_PATH = os.getcwd()\n",
    "TRAIN_DATA_PATH_PREFIX = CUR_PATH.replace(\"notebooks\", \"data\") + \"/datasets/train/\"\n",
    "VAL_DATA_PATH_PREFIX = CUR_PATH.replace(\"notebooks\", \"data\") + \"/datasets/validation/\"\n",
    "X_DATA_PATH = (TRAIN_DATA_PATH_PREFIX + \"x_data\").replace('\\\\', '/')\n",
    "Y_DATA_PATH = (TRAIN_DATA_PATH_PREFIX + \"y_data\").replace('\\\\', '/')\n",
    "\n",
    "VAL_X_DATA_PATH = (VAL_DATA_PATH_PREFIX + \"x_data\").replace('\\\\', '/')\n",
    "VAL_Y_DATA_PATH = (VAL_DATA_PATH_PREFIX + \"y_data\").replace('\\\\', '/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 257)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "instant_layer_normalization (In (None, 10, 257)      514         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 10, 257)      529420      instant_layer_normalization[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 10, 257)      0           input_1[0][0]                    \n",
      "                                                                 lstm[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 529,934\n",
      "Trainable params: 529,934\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_trainer = NAEC_model()\n",
    "model_trainer.create_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "model_trainer.compile_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train NAEC model\n",
      "Save path: None/NAEC_model/\n",
      "Load training data\n",
      "Found 1700 different chunks\n",
      "Training generator: <RepeatDataset shapes: ((32, 10, 257), (32, 10, 257)), types: (tf.float32, tf.float32)>\n",
      "Training steps count: 53\n",
      "Load validation data\n",
      "Found 1700 different chunks\n",
      "Validation generator: <RepeatDataset shapes: ((32, 10, 257), (32, 10, 257)), types: (tf.float32, tf.float32)>\n",
      "Validation steps count: 53\n",
      "53/53 [==============================] - 15s 237ms/step - loss: nan - accuracy: 0.8172 - val_loss: nan - val_accuracy: 0.7844\n",
      "\n",
      "Epoch 00001: val_loss did not improve from inf\n"
     ]
    }
   ],
   "source": [
    "runName = 'NAEC_model'\n",
    "model_trainer.train_model(runName, X_DATA_PATH, Y_DATA_PATH,\n",
    "                         VAL_X_DATA_PATH, VAL_Y_DATA_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}